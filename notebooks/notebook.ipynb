{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory 1 level up\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaetanpinon/code_projects/tests_&_interviews/mp_data/nba_career_prediction/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import logging\n",
    "import os\n",
    "from nba_career_predictor import NBACareerPredictor\n",
    "from parser import setup_parser\n",
    "import config\n",
    "import shap\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.offline as pyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results tracking\n",
    "# Initialize metrics_df with specific column names and data types\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': pd.Series(dtype='str'),\n",
    "    'Accuracy': pd.Series(dtype='float'),\n",
    "    'Precision': pd.Series(dtype='float'),\n",
    "    'Recall': pd.Series(dtype='float'),\n",
    "    'F1': pd.Series(dtype='float')\n",
    "})\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Load data\n",
    "logging.info(\"Loading data...\")\n",
    "df = pd.read_csv(config.DATA_PATH)\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = NBACareerPredictor()\n",
    "predictors_dict = {}\n",
    "\n",
    "# Add features\n",
    "logging.info(\"Adding smart features...\")\n",
    "enhanced_df = predictor.add_features(df)\n",
    "\n",
    "# Preprocess data\n",
    "X_train, X_test, y_train, y_test = predictor.preprocess_data(enhanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Logistic Regression\"\n",
    "# Create experiment directory\n",
    "experiment_name = f\"{model_name}_variance_testing\"\n",
    "experiment_dir = os.path.join(config.RESULTS_DIR, experiment_name)\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "seeds = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "\n",
    "# Train and evaluate each model\n",
    "for seed_number in seeds:\n",
    "    logging.info(\"-\" * 50)\n",
    "    logging.info(\" \" * 20)\n",
    "    logging.info(f\"Processing {model_name}...\")\n",
    "    logging.info(\"-\" * 20)\n",
    "    predictors_dict[model_name] = NBACareerPredictor(model_type=model_name, seed=seed_number)\n",
    "    \n",
    "    # Train and evaluate model, now returns more metrics\n",
    "    metrics, final_score, fpr, tpr, thresholds, youden_index, optimal_threshold, optimal_fpr, optimal_tpr = predictors_dict[model_name].train_and_test_model(\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )\n",
    "    \n",
    "    # Add metrics to the table\n",
    "    new_metrics_row = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1': metrics['f1']\n",
    "    }])\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, new_metrics_row], ignore_index=True)\n",
    "\n",
    "    # Plot ROC curve for model\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr, mode='lines',\n",
    "        name=model_name,\n",
    "        hovertemplate=(\"FPR: %{x:.2f}<br>\"+\"TPR: %{y:.2f}<br>\"+\"Threshold: %{customdata:.2f}<extra></extra>\"),\n",
    "        customdata=thresholds  # This adds the thresholds to the hover data\n",
    "    ))\n",
    "\n",
    "# Save metrics and ROC plot\n",
    "fig.update_layout(title=f\"ROC Curves of experiment {experiment_name}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
    "\n",
    "# Display metrics table and ROC curves plot\n",
    "logging.info(\"Final metrics table:\\n\" + str(metrics_df))\n",
    "pyo.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
