{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory 1 level up\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaetanpinon/code_projects/tests_&_interviews/mp_data/nba_career_prediction/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import logging\n",
    "import os\n",
    "from nba_career_predictor import NBACareerPredictor\n",
    "from parser import setup_parser\n",
    "import config\n",
    "import shap\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import plotly.offline as pyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results tracking\n",
    "# Initialize metrics_df with specific column names and data types\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': pd.Series(dtype='str'),\n",
    "    'Accuracy': pd.Series(dtype='float'),\n",
    "    'Precision': pd.Series(dtype='float'),\n",
    "    'Recall': pd.Series(dtype='float'),\n",
    "    'F1': pd.Series(dtype='float')\n",
    "})\n",
    "\n",
    "# Load data\n",
    "logging.info(\"Loading data...\")\n",
    "df = pd.read_csv(config.DATA_PATH)\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = NBACareerPredictor()\n",
    "predictors_dict = {}\n",
    "\n",
    "# Add features\n",
    "logging.info(\"Adding smart features...\")\n",
    "enhanced_df = predictor.add_features(df)\n",
    "\n",
    "# Preprocess data\n",
    "X_train, X_test, y_train, y_test = predictor.preprocess_data(enhanced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'temp-plot.html'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"Logistic Regression\"\n",
    "# Create experiment directory\n",
    "experiment_name = f\"{model_name}_variance_testing\"\n",
    "experiment_dir = os.path.join(config.RESULTS_DIR, experiment_name)\n",
    "os.makedirs(experiment_dir, exist_ok=True)\n",
    "\n",
    "seeds = [1, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "fig = go.Figure()\n",
    "# Train and evaluate each model\n",
    "for seed_number in seeds:\n",
    "    logging.info(\"-\" * 50)\n",
    "    logging.info(\" \" * 20)\n",
    "    logging.info(f\"Processing {model_name}...\")\n",
    "    logging.info(\"-\" * 20)\n",
    "    predictors_dict[model_name] = NBACareerPredictor(model_type=model_name, seed=seed_number)\n",
    "    \n",
    "    # Train and evaluate model, now returns more metrics\n",
    "    metrics, final_score, fpr, tpr, thresholds, youden_index, optimal_threshold, optimal_fpr, optimal_tpr = predictors_dict[model_name].train_and_test_model(\n",
    "        X_train, y_train, X_test, y_test\n",
    "    )\n",
    "    \n",
    "    # Add metrics to the table\n",
    "    new_metrics_row = pd.DataFrame([{\n",
    "        'Model': model_name,\n",
    "        'Accuracy': metrics['accuracy'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1': metrics['f1']\n",
    "    }])\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, new_metrics_row], ignore_index=True)\n",
    "\n",
    "    # Plot ROC curve for model\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=fpr, y=tpr, mode='lines',\n",
    "        name=model_name,\n",
    "        hovertemplate=(\"FPR: %{x:.2f}<br>\"+\"TPR: %{y:.2f}<br>\"+\"Threshold: %{customdata:.2f}<extra></extra>\"),\n",
    "        customdata=thresholds  # This adds the thresholds to the hover data\n",
    "    ))\n",
    "\n",
    "# Save metrics and ROC plot\n",
    "fig.update_layout(title=f\"ROC Curves of experiment {experiment_name}\", xaxis_title=\"False Positive Rate\", yaxis_title=\"True Positive Rate\")\n",
    "\n",
    "# Display metrics table and ROC curves plot\n",
    "logging.info(\"Final metrics table:\\n\" + str(metrics_df))\n",
    "pyo.plot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that variance of XGBoost and Gradient boosting are higher, probably because we overfit.\n",
    "Logistic regression has a way lower variance, performance don't change, like SVM and has the best results. and is more interpretable and has direct linear relations. \n",
    "We use Min-Max scaler. So could be more subject to overfit. We can look at the correlation matrix.\n",
    "Also logistic regression actually has better performances. So we keep it. \n",
    "We decide that we use the recall as we don't want to miss the next steph curry, even if we keep 4 other players on the bench. One key player is the most important.\n",
    "We set a limit of 80% false positives. 1 out of 5 will actually be one of our 5 key players. There are 5 players playing + a 6th men, and about 25 to 30 players in the team.\n",
    "Looking at this threshold of 80% we see all of our algorithms reach over 90% of recall. Logistic regression always reaches 95% of TPR at 80% FTP, is very regular, and doesn't overfit. it will be the most reliable model. Now we need to train our model on the entire cohort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
